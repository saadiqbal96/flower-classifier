{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0/GNgMNAJ73D9eKZP4Ce5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadiqbal96/cybersecuritytrivia/blob/main/PyTorchProject_html.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Import required libraries\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import json"
      ],
      "metadata": {
        "id": "kIXXond1Ifyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Data directories and transformations\n",
        "data_dir = 'path_to_data'  # placeholder path\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'\n",
        "\n",
        "# Define transforms for training, validation, and testing\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = valid_transforms\n",
        "\n",
        "# Load datasets (placeholder, no actual images needed for HTML)\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "valid_dataset = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "KnMctmaMIq-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Pretrained network and classifier\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Freeze parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Define a new feedforward classifier\n",
        "classifier = nn.Sequential(\n",
        "    nn.Linear(25088, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(512, 102),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")\n",
        "\n",
        "# Attach classifier to the model\n",
        "model.classifier = classifier"
      ],
      "metadata": {
        "id": "TiUaifmdIu58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Example training loop (do not run on iPhone)\n",
        "# This is just for display in HTML\n",
        "'''\n",
        "epochs = 5\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        # Forward pass\n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Training loss: {running_loss/len(train_loader)}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "4-II14HpI03D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Image processing and prediction functions\n",
        "def process_image(image_path):\n",
        "    \"\"\"Process a PIL image for use in a PyTorch model.\"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    # Example processing\n",
        "    return image\n",
        "\n",
        "def predict(image_path, model, topk=5):\n",
        "    \"\"\"Predict the class of an image using a trained model.\"\"\"\n",
        "    # Example prediction (not running)\n",
        "    print(f\"Top {topk} predicted classes for {image_path}\")"
      ],
      "metadata": {
        "id": "QtXegri-I6ka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}